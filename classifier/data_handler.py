import os
import json
import random
import pickle
import torch
import glob
from tqdm import tqdm
from torch.utils.data.dataset import Dataset
from tools.inference import init_model_from_ckpt, infer_from_filepath
from torch.utils.data.sampler import SubsetRandomSampler
import numpy as np

random.seed(123)



class MyDataset(Dataset):
    def __init__(self, id_label_pairs, obfuscated):
        self.id_label_pairs = id_label_pairs
        self.data = []
        self.dicts = []
        prefix = "obfuscated" if obfuscated else "nonobfuscated"
        if obfuscated:
            self.obf_map = get_obfuscation_mappings(id_label_pairs)
        # the dataset is supposed to be stored in a list of pairs [input, label]
        if os.path.exists("data/classifier_processed_%s.p"%prefix):
            self.data = pickle.load(open("data/classifier_processed_%s.p"%prefix,"rb"))
        else:
            model, _, _, _ = init_model_from_ckpt()
            print("Setting up dataset...")
            for dp in tqdm(id_label_pairs):
                new_dp = dict()
                id = dp[0]
                label = dp[1]
                filepath = self.get_path_obfuscated(id) if obfuscated else self.get_path_nonobfuscated(id)
                translation, hidden = infer_from_filepath(filepath, model)
                new_dp = {"id" : id,
                          "label": label,
                          "embedding" : hidden}
                self.dicts.append(new_dp)
                self.data.append([hidden.detach().tolist(), label])
            pickle.dump(self.data, open("data/classifier_processed_%s.p"%prefix,"wb"))
            print(self.dicts)
            pickle.dump(self.dicts, open("data/nlp_embeddings_400k_%s.p"%prefix,"wb"))

            print("Finished setting up dataset")

    def __getitem__(self, index):
        return self.data[index][0], self.data[index][1]

    def __len__(self):
        return len(self.data)

    def get_path_obfuscated(self, id):
        obf_path = os.path.join("mount", "final_400k", "small_obf_ast_token")
        paths = self.obf_map[id]
        path = random.choice(paths)
        filepath = os.path.join(obf_path, path)
        return filepath

    def get_path_nonobfuscated(self, id):
        filename = str(id) + ".ps1"
        filepath = os.path.join("mount","final_400k", "data", filename)
        return filepath

        


def load_data(batch_size, obfuscated=False):
    data = get_classifier_data()
    shuffle_dataset = True
    if obfuscated:
        print("Loading obfuscated data!")
    dataset = MyDataset(data, obfuscated)
    test_split = 0.3

    dataset_size = len(dataset)
    print("dataset size: ", dataset_size)
    indices = list(range(dataset_size))
    split = int(np.floor(test_split * dataset_size))
    if shuffle_dataset :
        np.random.seed(123)
        np.random.shuffle(indices)
    train_indices, test_indices = indices[split:], indices[:split]
    print("train indices: ", len(train_indices))
    print("test indices: ", len(test_indices))
    # Creating PT data samplers and loaders:
#    train_sampler = SubsetRandomSampler(train_indices)
#    test_sampler = SubsetRandomSampler(test_indices)
    train_data = [[dataset[idx][0], dataset[idx][1]] for idx in train_indices]
    test_data = [[dataset[idx][0], dataset[idx][1]] for idx in test_indices]
    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)
    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)
                                                        
    return train_loader, test_loader


def get_data(batch_size, obfuscated=False):
    print("Getting data, obfuscated: ", obfuscated)
    train_loader, test_loader = load_data(batch_size, obfuscated=obfuscated)
    x_train, y_train = zip(*train_loader.dataset)
    x_test, y_test = zip(*test_loader.dataset)
    x_train = torch.tensor(x_train)
    y_train = torch.tensor(y_train)
    x_test = torch.tensor(x_test)
    y_test = torch.tensor(y_test)
    return x_train, y_train, x_test, y_test


def get_merged(batch_size):
    print("Getting merged data...")
    x_train_non, y_train_non, x_test_non, y_test_non = get_data(batch_size, obfuscated=False)
    x_train_obf, y_train_obf, x_test_obf, y_test_obf = get_data(batch_size, obfuscated=True)
    x_train = torch.cat([x_train_non, x_train_obf], dim=0)
    y_train = torch.cat([y_train_non, y_train_obf], dim=0)
    x_test = torch.cat([x_test_non, x_test_obf], dim=0)
    y_test = torch.cat([y_test_non, y_test_obf], dim=0)
    return x_train, y_train, x_test, y_test


def get_classifier_data(dataset_root="mount/final_400k"):
    save_path = os.path.join("data", "clf_pairs.p")
    if os.path.exists(save_path):
        print("Loading saved data...")
        data = pickle.load(open(save_path, "rb"))
        return data
    label_path = os.path.join(dataset_root, "final_400k_labels.json")
    labels = json.load(open(label_path, "r"))

    benign_ids = []
    malware_ids = []

    for key, value in labels.items():
        if value["label"] is None:
            benign_ids.append(key)
        else:
            malware_ids.append(key)

    num_malware = len(malware_ids)
    final_benign_ids = random.sample(benign_ids, num_malware) # sample equal number of non-malware

    data = []
    for idx in range(num_malware):
        data.append([malware_ids[idx], 1])
        data.append([benign_ids[idx], 0])

    pickle.dump(data, open(save_path, "wb"))
    print("Saved data pairs!")
    return data


def get_obfuscation_mappings(id_label_pairs=None):
    if os.path.exists("data/classifier_obfuscation_map.json"):
        mapping = json.load(open("data/classifier_obfuscation_map.json","r"))
    else:
        if id_label_pairs is None:
            id_label_pairs = get_classifier_data()
        obf_path = os.path.join("mount", "final_400k", "small_obf_ast_token")
        mapping = dict()
        pbar = tqdm(total=97791*3)
        ids = set(dp[0] for dp in id_label_pairs)
        for file in os.listdir(obf_path):
            id = file.split("_")[0]
            if id in ids:
                if id in mapping:
                    mapping[id].append(file)
                else:
                    mapping[id] = [file]
            pbar.update()
        json.dump(mapping, open("data/classifier_obfuscation_map.json", "w"))
    return mapping




if __name__ == "__main__":
    data = get_classifier_data()
    print(data)
